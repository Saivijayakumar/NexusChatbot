{"ast":null,"code":"import { Subject } from 'rxjs';\nimport * as i0 from \"@angular/core\";\nimport * as i1 from \"@angular/common/http\";\nexport class BackendServiceService {\n  constructor(http) {\n    this.http = http;\n    this.isStoppedSpeechRecog = false;\n    this.text = '';\n    this.voiceToTextSubject = new Subject();\n    this.speakingPaused = new Subject();\n    this.tempWords = '';\n  }\n  postMethod(params) {\n    return this.http.post('http://localhost:5005/webhooks/rest/webhook', {\n      // return this.http.post('http://localhost:3000/gpt', {\n      ...params\n    });\n  }\n  speechInput() {\n    return this.voiceToTextSubject.asObservable();\n  }\n  readText(text) {\n    this.speech = new SpeechSynthesisUtterance();\n    this.speech.text = text;\n    this.speech.rate = 0.99;\n    this.speech.pitch = 1;\n    window.speechSynthesis.speak(this.speech);\n  }\n  init() {\n    this.recognition = new webkitSpeechRecognition();\n    this.recognition.interimResults = true;\n    this.recognition.lang = 'en-US';\n    this.recognition.addEventListener('result', e => {\n      const transcript = Array.from(e.results).map(result => result[0]).map(result => result.transcript).join('');\n      this.tempWords = transcript;\n      this.voiceToTextSubject.next(this.text || transcript);\n    });\n    return this.initListeners();\n  }\n  initListeners() {\n    this.recognition.addEventListener('end', condition => {\n      this.recognition.stop();\n    });\n    return this.speakingPaused.asObservable();\n  }\n  start() {\n    this.text = '';\n    this.isStoppedSpeechRecog = false;\n    this.recognition.start();\n    this.recognition.addEventListener('end', condition => {\n      if (this.isStoppedSpeechRecog) {\n        this.recognition.isActive = true;\n        this.recognition.stop();\n      } else {\n        this.isStoppedSpeechRecog = false;\n        this.wordConcat();\n        if (!this.recognition.lastActiveTime || Date.now() - this.recognition.lastActive > 200) {\n          this.recognition.start();\n          this.recognition.lastActive = Date.now();\n        }\n      }\n      this.voiceToTextSubject.next(this.text);\n    });\n  }\n  wordConcat() {\n    this.text = this.text.trim() + ' ' + this.tempWords;\n    this.text = this.text.trim();\n    this.tempWords = '';\n  }\n  stop() {\n    this.text = '';\n    this.isStoppedSpeechRecog = true;\n    this.wordConcat();\n    this.recognition.stop();\n    this.recognition.isActive = false;\n    this.speakingPaused.next('Stopped speaking');\n  }\n}\nBackendServiceService.ɵfac = function BackendServiceService_Factory(t) {\n  return new (t || BackendServiceService)(i0.ɵɵinject(i1.HttpClient));\n};\nBackendServiceService.ɵprov = /*@__PURE__*/i0.ɵɵdefineInjectable({\n  token: BackendServiceService,\n  factory: BackendServiceService.ɵfac,\n  providedIn: 'root'\n});","map":{"version":3,"mappings":"AAIA,SAASA,OAAO,QAAQ,MAAM;;;AAI9B,OAAM,MAAOC,qBAAqB;EAShCC,YAAoBC,IAAgB;IAAhB,SAAI,GAAJA,IAAI;IANxB,yBAAoB,GAAG,KAAK;IACrB,SAAI,GAAG,EAAE;IACR,uBAAkB,GAAoB,IAAIH,OAAO,EAAE;IACnD,mBAAc,GAAiB,IAAIA,OAAO,EAAE;IAC5C,cAAS,GAAW,EAAE;EAES;EAEvCI,UAAU,CAACC,MAAW;IACpB,OAAO,IAAI,CAACF,IAAI,CAACG,IAAI,CAAC,6CAA6C,EAAE;MACnE;MACA,GAAGD;KACJ,CAAC;EACJ;EAEAE,WAAW;IACT,OAAO,IAAI,CAACC,kBAAkB,CAACC,YAAY,EAAE;EAC/C;EACAC,QAAQ,CAACC,IAAY;IACnB,IAAI,CAACC,MAAM,GAAG,IAAIC,wBAAwB,EAAE;IAC5C,IAAI,CAACD,MAAM,CAACD,IAAI,GAAGA,IAAI;IACvB,IAAI,CAACC,MAAM,CAACE,IAAI,GAAG,IAAI;IACvB,IAAI,CAACF,MAAM,CAACG,KAAK,GAAG,CAAC;IACrBC,MAAM,CAACC,eAAe,CAACC,KAAK,CAAC,IAAI,CAACN,MAAM,CAAC;EAC3C;EAEAO,IAAI;IACF,IAAI,CAACC,WAAW,GAAG,IAAIC,uBAAuB,EAAE;IAEhD,IAAI,CAACD,WAAW,CAACE,cAAc,GAAG,IAAI;IACtC,IAAI,CAACF,WAAW,CAACG,IAAI,GAAG,OAAO;IAE/B,IAAI,CAACH,WAAW,CAACI,gBAAgB,CAAC,QAAQ,EAAGC,CAAM,IAAI;MACrD,MAAMC,UAAU,GAAGC,KAAK,CAACC,IAAI,CAACH,CAAC,CAACI,OAAO,CAAC,CACrCC,GAAG,CAAEC,MAAW,IAAKA,MAAM,CAAC,CAAC,CAAC,CAAC,CAC/BD,GAAG,CAAEC,MAAM,IAAKA,MAAM,CAACL,UAAU,CAAC,CAClCM,IAAI,CAAC,EAAE,CAAC;MACX,IAAI,CAACC,SAAS,GAAGP,UAAU;MAC3B,IAAI,CAAClB,kBAAkB,CAAC0B,IAAI,CAAC,IAAI,CAACvB,IAAI,IAAIe,UAAU,CAAC;IACvD,CAAC,CAAC;IACF,OAAO,IAAI,CAACS,aAAa,EAAE;EAC7B;EAEAA,aAAa;IACX,IAAI,CAACf,WAAW,CAACI,gBAAgB,CAAC,KAAK,EAAGY,SAAc,IAAI;MAC1D,IAAI,CAAChB,WAAW,CAACiB,IAAI,EAAE;IACzB,CAAC,CAAC;IACF,OAAO,IAAI,CAACC,cAAc,CAAC7B,YAAY,EAAE;EAC3C;EAEA8B,KAAK;IACH,IAAI,CAAC5B,IAAI,GAAG,EAAE;IACd,IAAI,CAAC6B,oBAAoB,GAAG,KAAK;IACjC,IAAI,CAACpB,WAAW,CAACmB,KAAK,EAAE;IACxB,IAAI,CAACnB,WAAW,CAACI,gBAAgB,CAAC,KAAK,EAAGY,SAAc,IAAI;MAC1D,IAAI,IAAI,CAACI,oBAAoB,EAAE;QAC7B,IAAI,CAACpB,WAAW,CAACqB,QAAQ,GAAG,IAAI;QAChC,IAAI,CAACrB,WAAW,CAACiB,IAAI,EAAE;OACxB,MAAM;QACL,IAAI,CAACG,oBAAoB,GAAG,KAAK;QACjC,IAAI,CAACE,UAAU,EAAE;QACjB,IACE,CAAC,IAAI,CAACtB,WAAW,CAACuB,cAAc,IAChCC,IAAI,CAACC,GAAG,EAAE,GAAG,IAAI,CAACzB,WAAW,CAAC0B,UAAU,GAAG,GAAG,EAC9C;UACA,IAAI,CAAC1B,WAAW,CAACmB,KAAK,EAAE;UACxB,IAAI,CAACnB,WAAW,CAAC0B,UAAU,GAAGF,IAAI,CAACC,GAAG,EAAE;;;MAG5C,IAAI,CAACrC,kBAAkB,CAAC0B,IAAI,CAAC,IAAI,CAACvB,IAAI,CAAC;IACzC,CAAC,CAAC;EACJ;EAEA+B,UAAU;IACR,IAAI,CAAC/B,IAAI,GAAG,IAAI,CAACA,IAAI,CAACoC,IAAI,EAAE,GAAG,GAAG,GAAG,IAAI,CAACd,SAAS;IACnD,IAAI,CAACtB,IAAI,GAAG,IAAI,CAACA,IAAI,CAACoC,IAAI,EAAE;IAC5B,IAAI,CAACd,SAAS,GAAG,EAAE;EACrB;EAEAI,IAAI;IACF,IAAI,CAAC1B,IAAI,GAAG,EAAE;IACd,IAAI,CAAC6B,oBAAoB,GAAG,IAAI;IAChC,IAAI,CAACE,UAAU,EAAE;IACjB,IAAI,CAACtB,WAAW,CAACiB,IAAI,EAAE;IACvB,IAAI,CAACjB,WAAW,CAACqB,QAAQ,GAAG,KAAK;IACjC,IAAI,CAACH,cAAc,CAACJ,IAAI,CAAC,kBAAkB,CAAC;EAC9C;;AAzFWjC,qBAAqB;mBAArBA,qBAAqB;AAAA;AAArBA,qBAAqB;SAArBA,qBAAqB;EAAA+C,SAArB/C,qBAAqB;EAAAgD,YAFpB;AAAM","names":["Subject","BackendServiceService","constructor","http","postMethod","params","post","speechInput","voiceToTextSubject","asObservable","readText","text","speech","SpeechSynthesisUtterance","rate","pitch","window","speechSynthesis","speak","init","recognition","webkitSpeechRecognition","interimResults","lang","addEventListener","e","transcript","Array","from","results","map","result","join","tempWords","next","initListeners","condition","stop","speakingPaused","start","isStoppedSpeechRecog","isActive","wordConcat","lastActiveTime","Date","now","lastActive","trim","factory","providedIn"],"sourceRoot":"","sources":["D:\\Chatbot UI\\src\\_services\\backend-service.service.ts"],"sourcesContent":["import { Injectable } from '@angular/core';\nimport { HttpClient } from '@angular/common/http';\ndeclare var webkitSpeechRecognition: any;\ndeclare var SpeechSynthesisUtterance: any;\nimport { Subject } from 'rxjs';\n@Injectable({\n  providedIn: 'root',\n})\nexport class BackendServiceService {\n  recognition: any;\n  speech: any;\n  isStoppedSpeechRecog = false;\n  public text = '';\n  private voiceToTextSubject: Subject<string> = new Subject();\n  private speakingPaused: Subject<any> = new Subject();\n  private tempWords: string = '';\n\n  constructor(private http: HttpClient) {}\n\n  postMethod(params: any) {\n    return this.http.post('http://localhost:5005/webhooks/rest/webhook', {\n      // return this.http.post('http://localhost:3000/gpt', {\n      ...params,\n    });\n  }\n\n  speechInput() {\n    return this.voiceToTextSubject.asObservable();\n  }\n  readText(text: String) {\n    this.speech = new SpeechSynthesisUtterance();\n    this.speech.text = text;\n    this.speech.rate = 0.99;\n    this.speech.pitch = 1;\n    window.speechSynthesis.speak(this.speech);\n  }\n\n  init() {\n    this.recognition = new webkitSpeechRecognition();\n\n    this.recognition.interimResults = true;\n    this.recognition.lang = 'en-US';\n\n    this.recognition.addEventListener('result', (e: any) => {\n      const transcript = Array.from(e.results)\n        .map((result: any) => result[0])\n        .map((result) => result.transcript)\n        .join('');\n      this.tempWords = transcript;\n      this.voiceToTextSubject.next(this.text || transcript);\n    });\n    return this.initListeners();\n  }\n\n  initListeners() {\n    this.recognition.addEventListener('end', (condition: any) => {\n      this.recognition.stop();\n    });\n    return this.speakingPaused.asObservable();\n  }\n\n  start() {\n    this.text = '';\n    this.isStoppedSpeechRecog = false;\n    this.recognition.start();\n    this.recognition.addEventListener('end', (condition: any) => {\n      if (this.isStoppedSpeechRecog) {\n        this.recognition.isActive = true;\n        this.recognition.stop();\n      } else {\n        this.isStoppedSpeechRecog = false;\n        this.wordConcat();\n        if (\n          !this.recognition.lastActiveTime ||\n          Date.now() - this.recognition.lastActive > 200\n        ) {\n          this.recognition.start();\n          this.recognition.lastActive = Date.now();\n        }\n      }\n      this.voiceToTextSubject.next(this.text);\n    });\n  }\n\n  wordConcat() {\n    this.text = this.text.trim() + ' ' + this.tempWords;\n    this.text = this.text.trim();\n    this.tempWords = '';\n  }\n\n  stop() {\n    this.text = '';\n    this.isStoppedSpeechRecog = true;\n    this.wordConcat();\n    this.recognition.stop();\n    this.recognition.isActive = false;\n    this.speakingPaused.next('Stopped speaking');\n  }\n}\n"]},"metadata":{},"sourceType":"module","externalDependencies":[]}